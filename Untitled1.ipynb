{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBc9pihEoBjx",
        "outputId": "888c2b01-a42b-4e49-8491-87eaa81bceea"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 配置验证通过\n",
            "改进后的模型结构验证:\n",
            "✅ 模型结构验证通过\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "\n",
            "运行实验组 Baseline，重复 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 特征维度验证通过\n",
            "实验: Baseline, Epoch [1/50], Train Loss: 2.0313, Val Loss: 1.5661, Val Acc: 0.4342, GPU峰值内存: 370.66 MB\n",
            "实验: Baseline, Epoch [2/50], Train Loss: 1.5473, Val Loss: 1.4285, Val Acc: 0.4860, GPU峰值内存: 373.66 MB\n",
            "实验: Baseline, Epoch [3/50], Train Loss: 1.2724, Val Loss: 1.3902, Val Acc: 0.5717, GPU峰值内存: 373.41 MB\n",
            "实验: Baseline, Epoch [4/50], Train Loss: 1.0937, Val Loss: 1.0324, Val Acc: 0.6414, GPU峰值内存: 373.11 MB\n",
            "实验: Baseline, Epoch [5/50], Train Loss: 0.9833, Val Loss: 1.0826, Val Acc: 0.6279, GPU峰值内存: 372.66 MB\n",
            "实验: Baseline, Epoch [6/50], Train Loss: 0.9192, Val Loss: 0.9336, Val Acc: 0.6703, GPU峰值内存: 372.91 MB\n",
            "实验: Baseline, Epoch [7/50], Train Loss: 0.8520, Val Loss: 0.8379, Val Acc: 0.7100, GPU峰值内存: 373.28 MB\n",
            "实验: Baseline, Epoch [8/50], Train Loss: 0.8005, Val Loss: 0.7972, Val Acc: 0.7260, GPU峰值内存: 373.28 MB\n",
            "实验: Baseline, Epoch [9/50], Train Loss: 0.7583, Val Loss: 0.7454, Val Acc: 0.7407, GPU峰值内存: 371.98 MB\n",
            "实验: Baseline, Epoch [10/50], Train Loss: 0.7139, Val Loss: 0.7663, Val Acc: 0.7457, GPU峰值内存: 373.28 MB\n",
            "实验: Baseline, Epoch [11/50], Train Loss: 0.6875, Val Loss: 0.7504, Val Acc: 0.7373, GPU峰值内存: 373.53 MB\n",
            "实验: Baseline, Epoch [12/50], Train Loss: 0.6608, Val Loss: 0.6951, Val Acc: 0.7550, GPU峰值内存: 374.91 MB\n",
            "实验: Baseline, Epoch [13/50], Train Loss: 0.6387, Val Loss: 0.6578, Val Acc: 0.7704, GPU峰值内存: 374.16 MB\n",
            "实验: Baseline, Epoch [14/50], Train Loss: 0.6102, Val Loss: 0.6354, Val Acc: 0.7804, GPU峰值内存: 372.41 MB\n",
            "实验: Baseline, Epoch [15/50], Train Loss: 0.5858, Val Loss: 0.6548, Val Acc: 0.7730, GPU峰值内存: 373.66 MB\n",
            "实验: Baseline, Epoch [16/50], Train Loss: 0.5752, Val Loss: 0.6151, Val Acc: 0.7862, GPU峰值内存: 373.66 MB\n",
            "实验: Baseline, Epoch [17/50], Train Loss: 0.5572, Val Loss: 0.6328, Val Acc: 0.7822, GPU峰值内存: 372.36 MB\n",
            "实验: Baseline, Epoch [18/50], Train Loss: 0.5401, Val Loss: 0.6190, Val Acc: 0.7879, GPU峰值内存: 372.61 MB\n",
            "实验: Baseline, Epoch [19/50], Train Loss: 0.5309, Val Loss: 0.6209, Val Acc: 0.7836, GPU峰值内存: 373.66 MB\n",
            "实验: Baseline, Epoch [20/50], Train Loss: 0.5075, Val Loss: 0.6577, Val Acc: 0.7800, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [21/50], Train Loss: 0.4943, Val Loss: 0.5898, Val Acc: 0.7962, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [22/50], Train Loss: 0.4888, Val Loss: 0.6141, Val Acc: 0.7913, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [23/50], Train Loss: 0.4738, Val Loss: 0.5749, Val Acc: 0.8065, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [24/50], Train Loss: 0.4598, Val Loss: 0.5664, Val Acc: 0.8047, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [25/50], Train Loss: 0.4566, Val Loss: 0.5454, Val Acc: 0.8138, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [26/50], Train Loss: 0.4365, Val Loss: 0.5891, Val Acc: 0.8091, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [27/50], Train Loss: 0.4310, Val Loss: 0.5585, Val Acc: 0.8160, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [28/50], Train Loss: 0.4207, Val Loss: 0.5573, Val Acc: 0.8129, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [29/50], Train Loss: 0.4133, Val Loss: 0.6192, Val Acc: 0.7952, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [30/50], Train Loss: 0.4096, Val Loss: 0.5468, Val Acc: 0.8145, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [31/50], Train Loss: 0.3986, Val Loss: 0.5809, Val Acc: 0.8095, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [32/50], Train Loss: 0.3891, Val Loss: 0.5682, Val Acc: 0.8121, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [33/50], Train Loss: 0.3872, Val Loss: 0.5610, Val Acc: 0.8157, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [34/50], Train Loss: 0.3743, Val Loss: 0.5753, Val Acc: 0.8167, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [35/50], Train Loss: 0.3686, Val Loss: 0.5746, Val Acc: 0.8187, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [36/50], Train Loss: 0.3629, Val Loss: 0.5235, Val Acc: 0.8263, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [37/50], Train Loss: 0.3491, Val Loss: 0.5477, Val Acc: 0.8226, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [38/50], Train Loss: 0.3506, Val Loss: 0.5377, Val Acc: 0.8267, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [39/50], Train Loss: 0.3468, Val Loss: 0.5882, Val Acc: 0.8121, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [40/50], Train Loss: 0.3348, Val Loss: 0.5658, Val Acc: 0.8200, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [41/50], Train Loss: 0.3298, Val Loss: 0.5833, Val Acc: 0.8212, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [42/50], Train Loss: 0.3252, Val Loss: 0.5749, Val Acc: 0.8196, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [43/50], Train Loss: 0.3207, Val Loss: 0.5572, Val Acc: 0.8229, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [44/50], Train Loss: 0.3127, Val Loss: 0.5859, Val Acc: 0.8229, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [45/50], Train Loss: 0.3123, Val Loss: 0.5360, Val Acc: 0.8255, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [46/50], Train Loss: 0.3124, Val Loss: 0.5875, Val Acc: 0.8189, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [47/50], Train Loss: 0.3088, Val Loss: 0.5835, Val Acc: 0.8180, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [48/50], Train Loss: 0.3002, Val Loss: 0.5697, Val Acc: 0.8254, GPU峰值内存: 372.03 MB\n",
            "实验: Baseline, Epoch [49/50], Train Loss: 0.2977, Val Loss: 0.5713, Val Acc: 0.8223, GPU峰值内存: 372.11 MB\n",
            "实验: Baseline, Epoch [50/50], Train Loss: 0.2914, Val Loss: 0.5580, Val Acc: 0.8271, GPU峰值内存: 372.03 MB\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-c98decfd6157>:457: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最终评估: Val Loss: 0.5235, Val Acc: 0.8263\n",
            "对称KL散度: 0.0004\n",
            "对抗样本准确率: 0.0490\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Baseline，重复 2\n",
            "✅ 特征维度验证通过\n",
            "实验: Baseline, Epoch [1/50], Train Loss: 1.9163, Val Loss: 1.3812, Val Acc: 0.4986, GPU峰值内存: 464.74 MB\n",
            "实验: Baseline, Epoch [2/50], Train Loss: 1.3407, Val Loss: 1.2019, Val Acc: 0.5730, GPU峰值内存: 463.82 MB\n",
            "实验: Baseline, Epoch [3/50], Train Loss: 1.1317, Val Loss: 1.1091, Val Acc: 0.6175, GPU峰值内存: 465.11 MB\n",
            "实验: Baseline, Epoch [4/50], Train Loss: 1.0013, Val Loss: 0.9797, Val Acc: 0.6656, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [5/50], Train Loss: 0.9152, Val Loss: 0.8797, Val Acc: 0.6904, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [6/50], Train Loss: 0.8481, Val Loss: 0.8245, Val Acc: 0.7134, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [7/50], Train Loss: 0.7888, Val Loss: 0.8365, Val Acc: 0.7114, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [8/50], Train Loss: 0.7403, Val Loss: 0.7954, Val Acc: 0.7190, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [9/50], Train Loss: 0.7107, Val Loss: 0.7417, Val Acc: 0.7418, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [10/50], Train Loss: 0.6797, Val Loss: 0.6701, Val Acc: 0.7685, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [11/50], Train Loss: 0.6457, Val Loss: 0.7168, Val Acc: 0.7518, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [12/50], Train Loss: 0.6218, Val Loss: 0.6638, Val Acc: 0.7683, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [13/50], Train Loss: 0.6004, Val Loss: 0.6632, Val Acc: 0.7756, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [14/50], Train Loss: 0.5828, Val Loss: 0.6827, Val Acc: 0.7675, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [15/50], Train Loss: 0.5616, Val Loss: 0.6232, Val Acc: 0.7907, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [16/50], Train Loss: 0.5432, Val Loss: 0.6418, Val Acc: 0.7815, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [17/50], Train Loss: 0.5236, Val Loss: 0.6083, Val Acc: 0.7935, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [18/50], Train Loss: 0.5153, Val Loss: 0.5967, Val Acc: 0.7969, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [19/50], Train Loss: 0.4963, Val Loss: 0.5755, Val Acc: 0.7988, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [20/50], Train Loss: 0.4853, Val Loss: 0.5960, Val Acc: 0.7976, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [21/50], Train Loss: 0.4715, Val Loss: 0.5540, Val Acc: 0.8166, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [22/50], Train Loss: 0.4617, Val Loss: 0.5590, Val Acc: 0.8124, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [23/50], Train Loss: 0.4498, Val Loss: 0.5709, Val Acc: 0.8052, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [24/50], Train Loss: 0.4444, Val Loss: 0.5384, Val Acc: 0.8150, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [25/50], Train Loss: 0.4336, Val Loss: 0.6054, Val Acc: 0.8011, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [26/50], Train Loss: 0.4219, Val Loss: 0.5885, Val Acc: 0.8032, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [27/50], Train Loss: 0.4162, Val Loss: 0.5644, Val Acc: 0.8152, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [28/50], Train Loss: 0.4085, Val Loss: 0.5631, Val Acc: 0.8128, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [29/50], Train Loss: 0.3933, Val Loss: 0.5677, Val Acc: 0.8122, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [30/50], Train Loss: 0.3835, Val Loss: 0.5932, Val Acc: 0.8048, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [31/50], Train Loss: 0.3832, Val Loss: 0.5474, Val Acc: 0.8208, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [32/50], Train Loss: 0.3759, Val Loss: 0.5694, Val Acc: 0.8141, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [33/50], Train Loss: 0.3667, Val Loss: 0.5714, Val Acc: 0.8120, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [34/50], Train Loss: 0.3566, Val Loss: 0.5663, Val Acc: 0.8192, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [35/50], Train Loss: 0.3518, Val Loss: 0.5265, Val Acc: 0.8296, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [36/50], Train Loss: 0.3499, Val Loss: 0.5408, Val Acc: 0.8247, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [37/50], Train Loss: 0.3450, Val Loss: 0.6001, Val Acc: 0.8063, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [38/50], Train Loss: 0.3300, Val Loss: 0.5899, Val Acc: 0.8205, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [39/50], Train Loss: 0.3322, Val Loss: 0.5227, Val Acc: 0.8311, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [40/50], Train Loss: 0.3251, Val Loss: 0.5434, Val Acc: 0.8273, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [41/50], Train Loss: 0.3272, Val Loss: 0.5567, Val Acc: 0.8213, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [42/50], Train Loss: 0.3162, Val Loss: 0.5656, Val Acc: 0.8199, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [43/50], Train Loss: 0.3129, Val Loss: 0.5802, Val Acc: 0.8267, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [44/50], Train Loss: 0.3077, Val Loss: 0.5286, Val Acc: 0.8313, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [45/50], Train Loss: 0.2997, Val Loss: 0.5577, Val Acc: 0.8273, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [46/50], Train Loss: 0.2989, Val Loss: 0.5491, Val Acc: 0.8343, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [47/50], Train Loss: 0.2957, Val Loss: 0.5399, Val Acc: 0.8356, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [48/50], Train Loss: 0.2918, Val Loss: 0.5546, Val Acc: 0.8330, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [49/50], Train Loss: 0.2962, Val Loss: 0.5462, Val Acc: 0.8301, GPU峰值内存: 464.07 MB\n",
            "实验: Baseline, Epoch [50/50], Train Loss: 0.2837, Val Loss: 0.5467, Val Acc: 0.8314, GPU峰值内存: 464.07 MB\n",
            "最终评估: Val Loss: 0.5227, Val Acc: 0.8311\n",
            "对称KL散度: 0.0008\n",
            "对抗样本准确率: 0.0486\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Baseline，重复 3\n",
            "✅ 特征维度验证通过\n",
            "实验: Baseline, Epoch [1/50], Train Loss: 1.9313, Val Loss: 1.4223, Val Acc: 0.4834, GPU峰值内存: 465.07 MB\n",
            "实验: Baseline, Epoch [2/50], Train Loss: 1.3651, Val Loss: 1.2075, Val Acc: 0.5778, GPU峰值内存: 466.77 MB\n",
            "实验: Baseline, Epoch [3/50], Train Loss: 1.1501, Val Loss: 1.1294, Val Acc: 0.5980, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [4/50], Train Loss: 1.0235, Val Loss: 0.9065, Val Acc: 0.6767, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [5/50], Train Loss: 0.9327, Val Loss: 0.9166, Val Acc: 0.6805, GPU峰值内存: 466.57 MB\n",
            "实验: Baseline, Epoch [6/50], Train Loss: 0.8669, Val Loss: 0.8084, Val Acc: 0.7182, GPU峰值内存: 466.77 MB\n",
            "实验: Baseline, Epoch [7/50], Train Loss: 0.8085, Val Loss: 0.7899, Val Acc: 0.7201, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [8/50], Train Loss: 0.7724, Val Loss: 0.7974, Val Acc: 0.7249, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [9/50], Train Loss: 0.7192, Val Loss: 0.7513, Val Acc: 0.7415, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [10/50], Train Loss: 0.6846, Val Loss: 0.6983, Val Acc: 0.7610, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [11/50], Train Loss: 0.6538, Val Loss: 0.6640, Val Acc: 0.7711, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [12/50], Train Loss: 0.6305, Val Loss: 0.7521, Val Acc: 0.7516, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [13/50], Train Loss: 0.6076, Val Loss: 0.6350, Val Acc: 0.7841, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [14/50], Train Loss: 0.5867, Val Loss: 0.6856, Val Acc: 0.7689, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [15/50], Train Loss: 0.5680, Val Loss: 0.6893, Val Acc: 0.7676, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [16/50], Train Loss: 0.5436, Val Loss: 0.6413, Val Acc: 0.7851, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [17/50], Train Loss: 0.5320, Val Loss: 0.6274, Val Acc: 0.7845, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [18/50], Train Loss: 0.5189, Val Loss: 0.5842, Val Acc: 0.8041, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [19/50], Train Loss: 0.5050, Val Loss: 0.5796, Val Acc: 0.8023, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [20/50], Train Loss: 0.4864, Val Loss: 0.5897, Val Acc: 0.7983, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [21/50], Train Loss: 0.4787, Val Loss: 0.6101, Val Acc: 0.7900, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [22/50], Train Loss: 0.4671, Val Loss: 0.6072, Val Acc: 0.8016, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [23/50], Train Loss: 0.4567, Val Loss: 0.5589, Val Acc: 0.8115, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [24/50], Train Loss: 0.4402, Val Loss: 0.5964, Val Acc: 0.8022, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [25/50], Train Loss: 0.4302, Val Loss: 0.5845, Val Acc: 0.8067, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [26/50], Train Loss: 0.4214, Val Loss: 0.5904, Val Acc: 0.8054, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [27/50], Train Loss: 0.4098, Val Loss: 0.5938, Val Acc: 0.8087, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [28/50], Train Loss: 0.4049, Val Loss: 0.5452, Val Acc: 0.8197, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [29/50], Train Loss: 0.3967, Val Loss: 0.5577, Val Acc: 0.8171, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [30/50], Train Loss: 0.3918, Val Loss: 0.5700, Val Acc: 0.8172, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [31/50], Train Loss: 0.3898, Val Loss: 0.5621, Val Acc: 0.8224, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [32/50], Train Loss: 0.3760, Val Loss: 0.5691, Val Acc: 0.8226, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [33/50], Train Loss: 0.3682, Val Loss: 0.5218, Val Acc: 0.8280, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [34/50], Train Loss: 0.3724, Val Loss: 0.5719, Val Acc: 0.8134, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [35/50], Train Loss: 0.3551, Val Loss: 0.5341, Val Acc: 0.8265, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [36/50], Train Loss: 0.3526, Val Loss: 0.5594, Val Acc: 0.8241, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [37/50], Train Loss: 0.3528, Val Loss: 0.5374, Val Acc: 0.8210, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [38/50], Train Loss: 0.3403, Val Loss: 0.5927, Val Acc: 0.8121, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [39/50], Train Loss: 0.3363, Val Loss: 0.5739, Val Acc: 0.8218, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [40/50], Train Loss: 0.3260, Val Loss: 0.5477, Val Acc: 0.8261, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [41/50], Train Loss: 0.3334, Val Loss: 0.5816, Val Acc: 0.8186, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [42/50], Train Loss: 0.3290, Val Loss: 0.5705, Val Acc: 0.8174, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [43/50], Train Loss: 0.3126, Val Loss: 0.5507, Val Acc: 0.8274, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [44/50], Train Loss: 0.3118, Val Loss: 0.5588, Val Acc: 0.8250, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [45/50], Train Loss: 0.3084, Val Loss: 0.5295, Val Acc: 0.8340, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [46/50], Train Loss: 0.2946, Val Loss: 0.5636, Val Acc: 0.8282, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [47/50], Train Loss: 0.2984, Val Loss: 0.5199, Val Acc: 0.8384, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [48/50], Train Loss: 0.2936, Val Loss: 0.5520, Val Acc: 0.8350, GPU峰值内存: 467.07 MB\n",
            "实验: Baseline, Epoch [49/50], Train Loss: 0.2956, Val Loss: 0.5707, Val Acc: 0.8256, GPU峰值内存: 466.52 MB\n",
            "实验: Baseline, Epoch [50/50], Train Loss: 0.2868, Val Loss: 0.5730, Val Acc: 0.8196, GPU峰值内存: 467.07 MB\n",
            "最终评估: Val Loss: 0.5199, Val Acc: 0.8384\n",
            "对称KL散度: 0.0007\n",
            "对抗样本准确率: 0.0448\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Rest-Wake (原始架构)，重复 1\n",
            "✅ 特征维度验证通过\n",
            "实验: Rest-Wake (原始架构), Epoch [1/50], Train Loss: 1.9700, Val Loss: 1.6839, Val Acc: 0.4527, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [2/50], Train Loss: 1.3969, Val Loss: 1.2749, Val Acc: 0.5415, GPU峰值内存: 462.69 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [3/50], Train Loss: 1.2069, Val Loss: 1.0506, Val Acc: 0.6301, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [4/50], Train Loss: 1.0359, Val Loss: 1.0460, Val Acc: 0.6391, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [5/50], Train Loss: 0.9371, Val Loss: 0.9794, Val Acc: 0.6647, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [6/50], Train Loss: 0.8856, Val Loss: 0.9420, Val Acc: 0.6916, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [7/50], Train Loss: 0.8195, Val Loss: 0.7999, Val Acc: 0.7231, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [8/50], Train Loss: 0.7950, Val Loss: 0.7999, Val Acc: 0.7231, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [9/50], Train Loss: 0.7700, Val Loss: 0.7806, Val Acc: 0.7305, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [10/50], Train Loss: 0.7290, Val Loss: 0.7252, Val Acc: 0.7482, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [11/50], Train Loss: 0.6969, Val Loss: 0.7451, Val Acc: 0.7420, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [12/50], Train Loss: 0.6679, Val Loss: 0.7183, Val Acc: 0.7504, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [13/50], Train Loss: 0.6435, Val Loss: 0.6621, Val Acc: 0.7672, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [14/50], Train Loss: 0.6126, Val Loss: 0.6389, Val Acc: 0.7820, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [15/50], Train Loss: 0.5845, Val Loss: 0.6395, Val Acc: 0.7775, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [16/50], Train Loss: 0.5822, Val Loss: 0.6395, Val Acc: 0.7775, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [17/50], Train Loss: 0.5740, Val Loss: 0.6236, Val Acc: 0.7869, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [18/50], Train Loss: 0.5562, Val Loss: 0.6174, Val Acc: 0.7878, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [19/50], Train Loss: 0.5366, Val Loss: 0.6251, Val Acc: 0.7842, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [20/50], Train Loss: 0.5197, Val Loss: 0.6322, Val Acc: 0.7878, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [21/50], Train Loss: 0.5085, Val Loss: 0.5839, Val Acc: 0.7995, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [22/50], Train Loss: 0.4988, Val Loss: 0.5860, Val Acc: 0.7950, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [23/50], Train Loss: 0.4835, Val Loss: 0.5651, Val Acc: 0.8091, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [24/50], Train Loss: 0.4824, Val Loss: 0.5651, Val Acc: 0.8091, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [25/50], Train Loss: 0.4733, Val Loss: 0.5548, Val Acc: 0.8089, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [26/50], Train Loss: 0.4583, Val Loss: 0.5817, Val Acc: 0.8080, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [27/50], Train Loss: 0.4485, Val Loss: 0.6266, Val Acc: 0.8023, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [28/50], Train Loss: 0.4527, Val Loss: 0.5865, Val Acc: 0.8053, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [29/50], Train Loss: 0.4370, Val Loss: 0.5609, Val Acc: 0.8137, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [30/50], Train Loss: 0.4216, Val Loss: 0.5609, Val Acc: 0.8137, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [31/50], Train Loss: 0.4233, Val Loss: 0.5609, Val Acc: 0.8137, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [32/50], Train Loss: 0.4228, Val Loss: 0.5609, Val Acc: 0.8137, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [33/50], Train Loss: 0.4203, Val Loss: 0.5606, Val Acc: 0.8175, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [34/50], Train Loss: 0.4126, Val Loss: 0.5516, Val Acc: 0.8169, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [35/50], Train Loss: 0.4027, Val Loss: 0.5712, Val Acc: 0.8059, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [36/50], Train Loss: 0.4019, Val Loss: 0.5653, Val Acc: 0.8197, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [37/50], Train Loss: 0.3868, Val Loss: 0.5768, Val Acc: 0.8137, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [38/50], Train Loss: 0.3797, Val Loss: 0.5617, Val Acc: 0.8166, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [39/50], Train Loss: 0.3775, Val Loss: 0.6057, Val Acc: 0.8045, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [40/50], Train Loss: 0.4236, Val Loss: 0.6057, Val Acc: 0.8045, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [41/50], Train Loss: 0.4298, Val Loss: 0.6057, Val Acc: 0.8045, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [42/50], Train Loss: 0.4269, Val Loss: 0.6057, Val Acc: 0.8045, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [43/50], Train Loss: 0.3638, Val Loss: 0.5233, Val Acc: 0.8314, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [44/50], Train Loss: 0.3661, Val Loss: 0.5624, Val Acc: 0.8229, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [45/50], Train Loss: 0.3592, Val Loss: 0.5542, Val Acc: 0.8221, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [46/50], Train Loss: 0.3730, Val Loss: 0.5542, Val Acc: 0.8221, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [47/50], Train Loss: 0.3700, Val Loss: 0.5542, Val Acc: 0.8221, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [48/50], Train Loss: 0.3678, Val Loss: 0.5542, Val Acc: 0.8221, GPU峰值内存: 464.19 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [49/50], Train Loss: 0.3524, Val Loss: 0.5534, Val Acc: 0.8245, GPU峰值内存: 462.89 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [50/50], Train Loss: 0.3417, Val Loss: 0.5672, Val Acc: 0.8175, GPU峰值内存: 464.19 MB\n",
            "最终评估: Val Loss: 0.5233, Val Acc: 0.8314\n",
            "对称KL散度: 0.0004\n",
            "对抗样本准确率: 0.0558\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Rest-Wake (原始架构)，重复 2\n",
            "✅ 特征维度验证通过\n",
            "实验: Rest-Wake (原始架构), Epoch [1/50], Train Loss: 1.9439, Val Loss: 1.4072, Val Acc: 0.4875, GPU峰值内存: 464.82 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [2/50], Train Loss: 1.3242, Val Loss: 1.1958, Val Acc: 0.5710, GPU峰值内存: 466.82 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [3/50], Train Loss: 1.1165, Val Loss: 1.0587, Val Acc: 0.6317, GPU峰值内存: 467.02 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [4/50], Train Loss: 0.9945, Val Loss: 0.9633, Val Acc: 0.6662, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [5/50], Train Loss: 0.9162, Val Loss: 0.9098, Val Acc: 0.6875, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [6/50], Train Loss: 0.8548, Val Loss: 0.7985, Val Acc: 0.7259, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [7/50], Train Loss: 0.7819, Val Loss: 0.7846, Val Acc: 0.7278, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [8/50], Train Loss: 0.7710, Val Loss: 0.7846, Val Acc: 0.7278, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [9/50], Train Loss: 0.7465, Val Loss: 0.8168, Val Acc: 0.7121, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [10/50], Train Loss: 0.7119, Val Loss: 0.6984, Val Acc: 0.7597, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [11/50], Train Loss: 0.6753, Val Loss: 0.8246, Val Acc: 0.7199, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [12/50], Train Loss: 0.6441, Val Loss: 0.6901, Val Acc: 0.7590, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [13/50], Train Loss: 0.6236, Val Loss: 0.6900, Val Acc: 0.7636, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [14/50], Train Loss: 0.5993, Val Loss: 0.6820, Val Acc: 0.7700, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [15/50], Train Loss: 0.5804, Val Loss: 0.6366, Val Acc: 0.7806, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [16/50], Train Loss: 0.5802, Val Loss: 0.6366, Val Acc: 0.7806, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [17/50], Train Loss: 0.5617, Val Loss: 0.6312, Val Acc: 0.7827, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [18/50], Train Loss: 0.5515, Val Loss: 0.5990, Val Acc: 0.7967, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [19/50], Train Loss: 0.5275, Val Loss: 0.5966, Val Acc: 0.7908, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [20/50], Train Loss: 0.5122, Val Loss: 0.5913, Val Acc: 0.7935, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [21/50], Train Loss: 0.4957, Val Loss: 0.5648, Val Acc: 0.8082, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [22/50], Train Loss: 0.4834, Val Loss: 0.5658, Val Acc: 0.8085, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [23/50], Train Loss: 0.4772, Val Loss: 0.5530, Val Acc: 0.8092, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [24/50], Train Loss: 0.4460, Val Loss: 0.5530, Val Acc: 0.8092, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [25/50], Train Loss: 0.4642, Val Loss: 0.5924, Val Acc: 0.8031, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [26/50], Train Loss: 0.4507, Val Loss: 0.5736, Val Acc: 0.8076, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [27/50], Train Loss: 0.4461, Val Loss: 0.5759, Val Acc: 0.8093, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [28/50], Train Loss: 0.4370, Val Loss: 0.5720, Val Acc: 0.8070, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [29/50], Train Loss: 0.4205, Val Loss: 0.6050, Val Acc: 0.8026, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [30/50], Train Loss: 0.4501, Val Loss: 0.6050, Val Acc: 0.8026, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [31/50], Train Loss: 0.4509, Val Loss: 0.6050, Val Acc: 0.8026, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [32/50], Train Loss: 0.4564, Val Loss: 0.6050, Val Acc: 0.8026, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [33/50], Train Loss: 0.4114, Val Loss: 0.6126, Val Acc: 0.8043, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [34/50], Train Loss: 0.4081, Val Loss: 0.5561, Val Acc: 0.8163, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [35/50], Train Loss: 0.3928, Val Loss: 0.5404, Val Acc: 0.8187, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [36/50], Train Loss: 0.3901, Val Loss: 0.5706, Val Acc: 0.8163, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [37/50], Train Loss: 0.3801, Val Loss: 0.5522, Val Acc: 0.8197, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [38/50], Train Loss: 0.3595, Val Loss: 0.5522, Val Acc: 0.8197, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [39/50], Train Loss: 0.3587, Val Loss: 0.5522, Val Acc: 0.8197, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [40/50], Train Loss: 0.3568, Val Loss: 0.5522, Val Acc: 0.8197, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [41/50], Train Loss: 0.3792, Val Loss: 0.5610, Val Acc: 0.8198, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [42/50], Train Loss: 0.3681, Val Loss: 0.5767, Val Acc: 0.8167, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [43/50], Train Loss: 0.3654, Val Loss: 0.6041, Val Acc: 0.8100, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [44/50], Train Loss: 0.3546, Val Loss: 0.5359, Val Acc: 0.8313, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [45/50], Train Loss: 0.3474, Val Loss: 0.5508, Val Acc: 0.8263, GPU峰值内存: 466.57 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [46/50], Train Loss: 0.3437, Val Loss: 0.5373, Val Acc: 0.8255, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [47/50], Train Loss: 0.3259, Val Loss: 0.5373, Val Acc: 0.8255, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [48/50], Train Loss: 0.3228, Val Loss: 0.5373, Val Acc: 0.8255, GPU峰值内存: 467.07 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [49/50], Train Loss: 0.3409, Val Loss: 0.5526, Val Acc: 0.8242, GPU峰值内存: 468.32 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [50/50], Train Loss: 0.3360, Val Loss: 0.5794, Val Acc: 0.8149, GPU峰值内存: 466.57 MB\n",
            "最终评估: Val Loss: 0.5359, Val Acc: 0.8313\n",
            "对称KL散度: 0.0004\n",
            "对抗样本准确率: 0.0571\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Rest-Wake (原始架构)，重复 3\n",
            "✅ 特征维度验证通过\n",
            "实验: Rest-Wake (原始架构), Epoch [1/50], Train Loss: 1.9161, Val Loss: 1.4680, Val Acc: 0.4820, GPU峰值内存: 466.36 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 303, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 136, in _remove_temp_dir\n",
            "    rmtree(tempdir, onerror=onerror)\n",
            "  File \"/usr/lib/python3.11/shutil.py\", line 763, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.11/shutil.py\", line 761, in rmtree\n",
            "    os.rmdir(path, dir_fd=dir_fd)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-ej936t7z'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "实验: Rest-Wake (原始架构), Epoch [2/50], Train Loss: 1.3588, Val Loss: 1.2360, Val Acc: 0.5663, GPU峰值内存: 467.61 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [3/50], Train Loss: 1.1477, Val Loss: 1.1590, Val Acc: 0.5896, GPU峰值内存: 465.61 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [4/50], Train Loss: 1.0196, Val Loss: 0.9211, Val Acc: 0.6725, GPU峰值内存: 465.99 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [5/50], Train Loss: 0.9331, Val Loss: 0.8928, Val Acc: 0.6875, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [6/50], Train Loss: 0.8625, Val Loss: 0.7983, Val Acc: 0.7265, GPU峰值内存: 465.69 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [7/50], Train Loss: 0.8066, Val Loss: 0.7880, Val Acc: 0.7215, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [8/50], Train Loss: 0.7903, Val Loss: 0.7880, Val Acc: 0.7215, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [9/50], Train Loss: 0.7531, Val Loss: 0.8095, Val Acc: 0.7206, GPU峰值内存: 465.69 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [10/50], Train Loss: 0.7191, Val Loss: 0.7280, Val Acc: 0.7493, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [11/50], Train Loss: 0.6833, Val Loss: 0.6800, Val Acc: 0.7655, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [12/50], Train Loss: 0.6552, Val Loss: 0.6759, Val Acc: 0.7662, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [13/50], Train Loss: 0.6311, Val Loss: 0.6484, Val Acc: 0.7833, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [14/50], Train Loss: 0.6030, Val Loss: 0.7238, Val Acc: 0.7605, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [15/50], Train Loss: 0.6566, Val Loss: 0.7238, Val Acc: 0.7605, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [16/50], Train Loss: 0.6539, Val Loss: 0.7238, Val Acc: 0.7605, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [17/50], Train Loss: 0.5849, Val Loss: 0.6308, Val Acc: 0.7864, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [18/50], Train Loss: 0.5637, Val Loss: 0.6347, Val Acc: 0.7859, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [19/50], Train Loss: 0.5453, Val Loss: 0.6004, Val Acc: 0.7944, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [20/50], Train Loss: 0.5293, Val Loss: 0.6251, Val Acc: 0.7878, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [21/50], Train Loss: 0.5124, Val Loss: 0.6498, Val Acc: 0.7770, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [22/50], Train Loss: 0.5610, Val Loss: 0.6498, Val Acc: 0.7770, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [23/50], Train Loss: 0.5590, Val Loss: 0.6498, Val Acc: 0.7770, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [24/50], Train Loss: 0.5567, Val Loss: 0.6498, Val Acc: 0.7770, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [25/50], Train Loss: 0.5003, Val Loss: 0.6197, Val Acc: 0.7891, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [26/50], Train Loss: 0.4839, Val Loss: 0.5702, Val Acc: 0.8100, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [27/50], Train Loss: 0.4707, Val Loss: 0.5901, Val Acc: 0.7994, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [28/50], Train Loss: 0.4634, Val Loss: 0.5646, Val Acc: 0.8101, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [29/50], Train Loss: 0.4513, Val Loss: 0.5977, Val Acc: 0.7981, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [30/50], Train Loss: 0.4513, Val Loss: 0.5977, Val Acc: 0.7981, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [31/50], Train Loss: 0.4516, Val Loss: 0.5977, Val Acc: 0.7981, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [32/50], Train Loss: 0.4439, Val Loss: 0.5977, Val Acc: 0.7981, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [33/50], Train Loss: 0.4401, Val Loss: 0.5675, Val Acc: 0.8087, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [34/50], Train Loss: 0.4362, Val Loss: 0.5691, Val Acc: 0.8115, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [35/50], Train Loss: 0.4216, Val Loss: 0.6031, Val Acc: 0.8004, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [36/50], Train Loss: 0.4195, Val Loss: 0.5434, Val Acc: 0.8228, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [37/50], Train Loss: 0.4042, Val Loss: 0.5804, Val Acc: 0.8083, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [38/50], Train Loss: 0.3934, Val Loss: 0.5497, Val Acc: 0.8196, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [39/50], Train Loss: 0.3936, Val Loss: 0.6048, Val Acc: 0.8047, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [40/50], Train Loss: 0.4094, Val Loss: 0.6048, Val Acc: 0.8047, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [41/50], Train Loss: 0.4084, Val Loss: 0.6048, Val Acc: 0.8047, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [42/50], Train Loss: 0.4097, Val Loss: 0.6048, Val Acc: 0.8047, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [43/50], Train Loss: 0.3843, Val Loss: 0.5512, Val Acc: 0.8196, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [44/50], Train Loss: 0.3723, Val Loss: 0.5728, Val Acc: 0.8086, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [45/50], Train Loss: 0.3692, Val Loss: 0.5559, Val Acc: 0.8186, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [46/50], Train Loss: 0.3559, Val Loss: 0.5656, Val Acc: 0.8200, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [47/50], Train Loss: 0.3366, Val Loss: 0.5656, Val Acc: 0.8200, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [48/50], Train Loss: 0.3358, Val Loss: 0.5656, Val Acc: 0.8200, GPU峰值内存: 466.74 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [49/50], Train Loss: 0.3581, Val Loss: 0.5492, Val Acc: 0.8195, GPU峰值内存: 465.24 MB\n",
            "实验: Rest-Wake (原始架构), Epoch [50/50], Train Loss: 0.3547, Val Loss: 0.5900, Val Acc: 0.8147, GPU峰值内存: 466.74 MB\n",
            "最终评估: Val Loss: 0.5434, Val Acc: 0.8228\n",
            "对称KL散度: 0.0014\n",
            "对抗样本准确率: 0.0549\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Rest-Wake (改进架构)，重复 1\n",
            "✅ 特征维度验证通过\n",
            "实验: Rest-Wake (改进架构), Epoch [1/50], Train Loss: 1.6855, Val Loss: 1.3273, Val Acc: 0.5188, GPU峰值内存: 483.93 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [2/50], Train Loss: 1.2026, Val Loss: 1.0755, Val Acc: 0.6102, GPU峰值内存: 488.48 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [3/50], Train Loss: 1.0351, Val Loss: 0.9981, Val Acc: 0.6516, GPU峰值内存: 486.48 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [4/50], Train Loss: 0.9320, Val Loss: 0.8853, Val Acc: 0.6924, GPU峰值内存: 486.85 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [5/50], Train Loss: 0.8561, Val Loss: 0.8436, Val Acc: 0.7037, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [6/50], Train Loss: 0.8014, Val Loss: 0.7905, Val Acc: 0.7288, GPU峰值内存: 486.56 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [7/50], Train Loss: 0.7568, Val Loss: 0.7517, Val Acc: 0.7430, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [8/50], Train Loss: 0.7459, Val Loss: 0.7517, Val Acc: 0.7430, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [9/50], Train Loss: 0.7220, Val Loss: 0.7613, Val Acc: 0.7370, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [10/50], Train Loss: 0.6859, Val Loss: 0.6915, Val Acc: 0.7628, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [11/50], Train Loss: 0.6583, Val Loss: 0.6833, Val Acc: 0.7629, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [12/50], Train Loss: 0.6346, Val Loss: 0.6420, Val Acc: 0.7723, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [13/50], Train Loss: 0.6047, Val Loss: 0.6288, Val Acc: 0.7832, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [14/50], Train Loss: 0.5926, Val Loss: 0.6495, Val Acc: 0.7762, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [15/50], Train Loss: 0.5662, Val Loss: 0.6183, Val Acc: 0.7887, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [16/50], Train Loss: 0.5590, Val Loss: 0.6183, Val Acc: 0.7887, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [17/50], Train Loss: 0.5513, Val Loss: 0.6147, Val Acc: 0.7893, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [18/50], Train Loss: 0.5341, Val Loss: 0.6033, Val Acc: 0.7922, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [19/50], Train Loss: 0.5209, Val Loss: 0.5797, Val Acc: 0.7997, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [20/50], Train Loss: 0.4970, Val Loss: 0.6230, Val Acc: 0.7908, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [21/50], Train Loss: 0.4862, Val Loss: 0.5709, Val Acc: 0.8048, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [22/50], Train Loss: 0.4763, Val Loss: 0.5842, Val Acc: 0.8033, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [23/50], Train Loss: 0.4928, Val Loss: 0.5842, Val Acc: 0.8033, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [24/50], Train Loss: 0.4967, Val Loss: 0.5842, Val Acc: 0.8033, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [25/50], Train Loss: 0.4672, Val Loss: 0.5598, Val Acc: 0.8076, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [26/50], Train Loss: 0.4435, Val Loss: 0.5648, Val Acc: 0.8114, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [27/50], Train Loss: 0.4450, Val Loss: 0.5515, Val Acc: 0.8154, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [28/50], Train Loss: 0.4237, Val Loss: 0.5973, Val Acc: 0.8015, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [29/50], Train Loss: 0.4296, Val Loss: 0.5738, Val Acc: 0.8096, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [30/50], Train Loss: 0.4556, Val Loss: 0.5738, Val Acc: 0.8096, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [31/50], Train Loss: 0.4530, Val Loss: 0.5738, Val Acc: 0.8096, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [32/50], Train Loss: 0.4546, Val Loss: 0.5738, Val Acc: 0.8096, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [33/50], Train Loss: 0.4109, Val Loss: 0.5696, Val Acc: 0.8205, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [34/50], Train Loss: 0.4073, Val Loss: 0.5696, Val Acc: 0.8131, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [35/50], Train Loss: 0.4024, Val Loss: 0.5536, Val Acc: 0.8165, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [36/50], Train Loss: 0.3895, Val Loss: 0.5838, Val Acc: 0.8068, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [37/50], Train Loss: 0.3824, Val Loss: 0.5249, Val Acc: 0.8221, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [38/50], Train Loss: 0.3681, Val Loss: 0.5480, Val Acc: 0.8204, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [39/50], Train Loss: 0.3690, Val Loss: 0.5587, Val Acc: 0.8162, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [40/50], Train Loss: 0.3582, Val Loss: 0.5659, Val Acc: 0.8161, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [41/50], Train Loss: 0.3709, Val Loss: 0.5659, Val Acc: 0.8161, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [42/50], Train Loss: 0.3708, Val Loss: 0.5659, Val Acc: 0.8161, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [43/50], Train Loss: 0.3511, Val Loss: 0.5221, Val Acc: 0.8266, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [44/50], Train Loss: 0.3432, Val Loss: 0.5523, Val Acc: 0.8231, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [45/50], Train Loss: 0.3428, Val Loss: 0.5321, Val Acc: 0.8290, GPU峰值内存: 487.60 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [46/50], Train Loss: 0.3349, Val Loss: 0.5535, Val Acc: 0.8265, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [47/50], Train Loss: 0.3374, Val Loss: 0.5535, Val Acc: 0.8265, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [48/50], Train Loss: 0.3410, Val Loss: 0.5535, Val Acc: 0.8265, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [49/50], Train Loss: 0.3373, Val Loss: 0.5535, Val Acc: 0.8265, GPU峰值内存: 486.31 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [50/50], Train Loss: 0.3278, Val Loss: 0.5902, Val Acc: 0.8115, GPU峰值内存: 487.60 MB\n",
            "最终评估: Val Loss: 0.5221, Val Acc: 0.8266\n",
            "对称KL散度: 0.0010\n",
            "对抗样本准确率: 0.0578\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Rest-Wake (改进架构)，重复 2\n",
            "✅ 特征维度验证通过\n",
            "实验: Rest-Wake (改进架构), Epoch [1/50], Train Loss: 1.6611, Val Loss: 1.3705, Val Acc: 0.5192, GPU峰值内存: 487.37 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [2/50], Train Loss: 1.1910, Val Loss: 1.0688, Val Acc: 0.6222, GPU峰值内存: 486.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [3/50], Train Loss: 1.0249, Val Loss: 0.9513, Val Acc: 0.6610, GPU峰值内存: 486.75 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [4/50], Train Loss: 0.9207, Val Loss: 0.9204, Val Acc: 0.6792, GPU峰值内存: 486.75 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [5/50], Train Loss: 0.8444, Val Loss: 0.8501, Val Acc: 0.7062, GPU峰值内存: 485.67 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [6/50], Train Loss: 0.7850, Val Loss: 0.7704, Val Acc: 0.7354, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [7/50], Train Loss: 0.7361, Val Loss: 0.7617, Val Acc: 0.7303, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [8/50], Train Loss: 0.7609, Val Loss: 0.7617, Val Acc: 0.7303, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [9/50], Train Loss: 0.7031, Val Loss: 0.7687, Val Acc: 0.7280, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [10/50], Train Loss: 0.6648, Val Loss: 0.6895, Val Acc: 0.7628, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [11/50], Train Loss: 0.6377, Val Loss: 0.7265, Val Acc: 0.7441, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [12/50], Train Loss: 0.6165, Val Loss: 0.6806, Val Acc: 0.7657, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [13/50], Train Loss: 0.5864, Val Loss: 0.6313, Val Acc: 0.7826, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [14/50], Train Loss: 0.5748, Val Loss: 0.6673, Val Acc: 0.7710, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [15/50], Train Loss: 0.5981, Val Loss: 0.6673, Val Acc: 0.7710, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [16/50], Train Loss: 0.5956, Val Loss: 0.6673, Val Acc: 0.7710, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [17/50], Train Loss: 0.5569, Val Loss: 0.6538, Val Acc: 0.7811, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [18/50], Train Loss: 0.5341, Val Loss: 0.6493, Val Acc: 0.7814, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [19/50], Train Loss: 0.5165, Val Loss: 0.5903, Val Acc: 0.7972, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [20/50], Train Loss: 0.5059, Val Loss: 0.5880, Val Acc: 0.7977, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [21/50], Train Loss: 0.4854, Val Loss: 0.5529, Val Acc: 0.8140, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [22/50], Train Loss: 0.4813, Val Loss: 0.5559, Val Acc: 0.8148, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [23/50], Train Loss: 0.4690, Val Loss: 0.5628, Val Acc: 0.8073, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [24/50], Train Loss: 0.4627, Val Loss: 0.5628, Val Acc: 0.8073, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [25/50], Train Loss: 0.4550, Val Loss: 0.5377, Val Acc: 0.8177, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [26/50], Train Loss: 0.4399, Val Loss: 0.5341, Val Acc: 0.8249, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [27/50], Train Loss: 0.4326, Val Loss: 0.5274, Val Acc: 0.8267, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [28/50], Train Loss: 0.4157, Val Loss: 0.5748, Val Acc: 0.8135, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [29/50], Train Loss: 0.4141, Val Loss: 0.5517, Val Acc: 0.8175, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [30/50], Train Loss: 0.4080, Val Loss: 0.5379, Val Acc: 0.8221, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [31/50], Train Loss: 0.3843, Val Loss: 0.5379, Val Acc: 0.8221, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [32/50], Train Loss: 0.3817, Val Loss: 0.5379, Val Acc: 0.8221, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [33/50], Train Loss: 0.3994, Val Loss: 0.6033, Val Acc: 0.8077, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [34/50], Train Loss: 0.3905, Val Loss: 0.5593, Val Acc: 0.8195, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [35/50], Train Loss: 0.3808, Val Loss: 0.5441, Val Acc: 0.8206, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [36/50], Train Loss: 0.3750, Val Loss: 0.5290, Val Acc: 0.8261, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [37/50], Train Loss: 0.3688, Val Loss: 0.5178, Val Acc: 0.8320, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [38/50], Train Loss: 0.3415, Val Loss: 0.5178, Val Acc: 0.8320, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [39/50], Train Loss: 0.3402, Val Loss: 0.5178, Val Acc: 0.8320, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [40/50], Train Loss: 0.3400, Val Loss: 0.5178, Val Acc: 0.8320, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [41/50], Train Loss: 0.3526, Val Loss: 0.5542, Val Acc: 0.8216, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [42/50], Train Loss: 0.3579, Val Loss: 0.5542, Val Acc: 0.8216, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [43/50], Train Loss: 0.3521, Val Loss: 0.5136, Val Acc: 0.8333, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [44/50], Train Loss: 0.3434, Val Loss: 0.5694, Val Acc: 0.8192, GPU峰值内存: 486.04 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [45/50], Train Loss: 0.3439, Val Loss: 0.5474, Val Acc: 0.8219, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [46/50], Train Loss: 0.3485, Val Loss: 0.5474, Val Acc: 0.8219, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [47/50], Train Loss: 0.3454, Val Loss: 0.5474, Val Acc: 0.8219, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [48/50], Train Loss: 0.3471, Val Loss: 0.5474, Val Acc: 0.8219, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [49/50], Train Loss: 0.3311, Val Loss: 0.5206, Val Acc: 0.8330, GPU峰值内存: 487.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [50/50], Train Loss: 0.3243, Val Loss: 0.5274, Val Acc: 0.8346, GPU峰值内存: 486.04 MB\n",
            "最终评估: Val Loss: 0.5136, Val Acc: 0.8333\n",
            "对称KL散度: 0.0002\n",
            "对抗样本准确率: 0.0509\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "\n",
            "运行实验组 Rest-Wake (改进架构)，重复 3\n",
            "✅ 特征维度验证通过\n",
            "实验: Rest-Wake (改进架构), Epoch [1/50], Train Loss: 1.6761, Val Loss: 1.3918, Val Acc: 0.4972, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [2/50], Train Loss: 1.1947, Val Loss: 1.1654, Val Acc: 0.5915, GPU峰值内存: 485.54 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [3/50], Train Loss: 1.0155, Val Loss: 0.9771, Val Acc: 0.6510, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [4/50], Train Loss: 0.9275, Val Loss: 0.9060, Val Acc: 0.6832, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [5/50], Train Loss: 0.8511, Val Loss: 0.7955, Val Acc: 0.7177, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [6/50], Train Loss: 0.7929, Val Loss: 0.7897, Val Acc: 0.7185, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [7/50], Train Loss: 0.7454, Val Loss: 0.7769, Val Acc: 0.7302, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [8/50], Train Loss: 0.7435, Val Loss: 0.7769, Val Acc: 0.7302, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [9/50], Train Loss: 0.7241, Val Loss: 0.7699, Val Acc: 0.7347, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [10/50], Train Loss: 0.6887, Val Loss: 0.6635, Val Acc: 0.7692, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [11/50], Train Loss: 0.6471, Val Loss: 0.7068, Val Acc: 0.7562, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [12/50], Train Loss: 0.6285, Val Loss: 0.6553, Val Acc: 0.7737, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [13/50], Train Loss: 0.6025, Val Loss: 0.6800, Val Acc: 0.7611, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [14/50], Train Loss: 0.5776, Val Loss: 0.6418, Val Acc: 0.7817, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [15/50], Train Loss: 0.5629, Val Loss: 0.6020, Val Acc: 0.7875, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [16/50], Train Loss: 0.5348, Val Loss: 0.6020, Val Acc: 0.7875, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [17/50], Train Loss: 0.5470, Val Loss: 0.5853, Val Acc: 0.7993, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [18/50], Train Loss: 0.5311, Val Loss: 0.6126, Val Acc: 0.7893, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [19/50], Train Loss: 0.5192, Val Loss: 0.5859, Val Acc: 0.7960, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [20/50], Train Loss: 0.5029, Val Loss: 0.5827, Val Acc: 0.7964, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [21/50], Train Loss: 0.4879, Val Loss: 0.5626, Val Acc: 0.8072, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [22/50], Train Loss: 0.4756, Val Loss: 0.5864, Val Acc: 0.8028, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [23/50], Train Loss: 0.4891, Val Loss: 0.5864, Val Acc: 0.8028, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [24/50], Train Loss: 0.4890, Val Loss: 0.5864, Val Acc: 0.8028, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [25/50], Train Loss: 0.4643, Val Loss: 0.5775, Val Acc: 0.8077, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [26/50], Train Loss: 0.4528, Val Loss: 0.6067, Val Acc: 0.7986, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [27/50], Train Loss: 0.4763, Val Loss: 0.6067, Val Acc: 0.7986, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [28/50], Train Loss: 0.4771, Val Loss: 0.6067, Val Acc: 0.7986, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [29/50], Train Loss: 0.4482, Val Loss: 0.5603, Val Acc: 0.8171, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [30/50], Train Loss: 0.4377, Val Loss: 0.5781, Val Acc: 0.8052, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [31/50], Train Loss: 0.4254, Val Loss: 0.5881, Val Acc: 0.8064, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [32/50], Train Loss: 0.4145, Val Loss: 0.5337, Val Acc: 0.8203, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [33/50], Train Loss: 0.4088, Val Loss: 0.5856, Val Acc: 0.8059, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [34/50], Train Loss: 0.4356, Val Loss: 0.5856, Val Acc: 0.8059, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [35/50], Train Loss: 0.4367, Val Loss: 0.5856, Val Acc: 0.8059, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [36/50], Train Loss: 0.3955, Val Loss: 0.5475, Val Acc: 0.8169, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [37/50], Train Loss: 0.3897, Val Loss: 0.5575, Val Acc: 0.8169, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [38/50], Train Loss: 0.3772, Val Loss: 0.5972, Val Acc: 0.8093, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [39/50], Train Loss: 0.3739, Val Loss: 0.5301, Val Acc: 0.8202, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [40/50], Train Loss: 0.3710, Val Loss: 0.5186, Val Acc: 0.8303, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [41/50], Train Loss: 0.3407, Val Loss: 0.5186, Val Acc: 0.8303, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [42/50], Train Loss: 0.3417, Val Loss: 0.5186, Val Acc: 0.8303, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [43/50], Train Loss: 0.3629, Val Loss: 0.5529, Val Acc: 0.8237, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [44/50], Train Loss: 0.3485, Val Loss: 0.5514, Val Acc: 0.8225, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [45/50], Train Loss: 0.3464, Val Loss: 0.5610, Val Acc: 0.8181, GPU峰值内存: 486.59 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [46/50], Train Loss: 0.3408, Val Loss: 0.5463, Val Acc: 0.8247, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [47/50], Train Loss: 0.3377, Val Loss: 0.5463, Val Acc: 0.8247, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [48/50], Train Loss: 0.3345, Val Loss: 0.5463, Val Acc: 0.8247, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [49/50], Train Loss: 0.3386, Val Loss: 0.5463, Val Acc: 0.8247, GPU峰值内存: 485.29 MB\n",
            "实验: Rest-Wake (改进架构), Epoch [50/50], Train Loss: 0.3365, Val Loss: 0.5377, Val Acc: 0.8207, GPU峰值内存: 486.59 MB\n",
            "最终评估: Val Loss: 0.5186, Val Acc: 0.8303\n",
            "对称KL散度: 0.0007\n",
            "对抗样本准确率: 0.0553\n",
            "特征稳定性 (标准差平均): 0.0000\n",
            "显存压缩比: 0.2000\n",
            "                  count      mean       std     min      25%     50%      75%  \\\n",
            "exp                                                                             \n",
            "Baseline            3.0  0.826033  0.005972  0.8196  0.82335  0.8271  0.82925   \n",
            "Rest-Wake (原始架构)    3.0  0.815700  0.001562  0.8147  0.81480  0.8149  0.81620   \n",
            "Rest-Wake (改进架构)    3.0  0.822267  0.011629  0.8115  0.81610  0.8207  0.82765   \n",
            "\n",
            "                     max  \n",
            "exp                       \n",
            "Baseline          0.8314  \n",
            "Rest-Wake (原始架构)  0.8175  \n",
            "Rest-Wake (改进架构)  0.8346  \n",
            "配对 t 检验 p 值: 0.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c98decfd6157>:329: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-1-c98decfd6157>:329: UserWarning: Glyph 22987 (\\N{CJK UNIFIED IDEOGRAPH-59CB}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-1-c98decfd6157>:329: UserWarning: Glyph 26550 (\\N{CJK UNIFIED IDEOGRAPH-67B6}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-1-c98decfd6157>:329: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-1-c98decfd6157>:329: UserWarning: Glyph 25913 (\\N{CJK UNIFIED IDEOGRAPH-6539}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-1-c98decfd6157>:329: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-1-c98decfd6157>:330: UserWarning: Glyph 21407 (\\N{CJK UNIFIED IDEOGRAPH-539F}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"training_curves.png\")\n",
            "<ipython-input-1-c98decfd6157>:330: UserWarning: Glyph 22987 (\\N{CJK UNIFIED IDEOGRAPH-59CB}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"training_curves.png\")\n",
            "<ipython-input-1-c98decfd6157>:330: UserWarning: Glyph 26550 (\\N{CJK UNIFIED IDEOGRAPH-67B6}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"training_curves.png\")\n",
            "<ipython-input-1-c98decfd6157>:330: UserWarning: Glyph 26500 (\\N{CJK UNIFIED IDEOGRAPH-6784}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"training_curves.png\")\n",
            "<ipython-input-1-c98decfd6157>:330: UserWarning: Glyph 25913 (\\N{CJK UNIFIED IDEOGRAPH-6539}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"training_curves.png\")\n",
            "<ipython-input-1-c98decfd6157>:330: UserWarning: Glyph 36827 (\\N{CJK UNIFIED IDEOGRAPH-8FDB}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(\"training_curves.png\")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models.resnet import ResNet\n",
        "from torchvision.models import resnet18\n",
        "from scipy.stats import entropy\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##############################################\n",
        "# 1. 定义 Mish 激活函数\n",
        "##############################################\n",
        "class Mish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "##############################################\n",
        "# 2. 定义 SE 模块\n",
        "##############################################\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = x.view(b, c, -1).mean(dim=2)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "##############################################\n",
        "# 3. 递归替换所有 ReLU 为 Mish\n",
        "##############################################\n",
        "def replace_activation(model, old_layer=nn.ReLU, new_layer=Mish):\n",
        "    for name, child in model.named_children():\n",
        "        if isinstance(child, old_layer):\n",
        "            setattr(model, name, new_layer())\n",
        "        else:\n",
        "            replace_activation(child, old_layer, new_layer)\n",
        "\n",
        "##############################################\n",
        "# 4. 定义 SEBasicBlock（兼容 ResNet 构造函数）\n",
        "##############################################\n",
        "class SEBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
        "                 groups=1, base_width=64, dilation=1, norm_layer=None, reduction=16):\n",
        "        super(SEBasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('SEBasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in SEBasicBlock\")\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = Mish()  # 使用 Mish 替换 ReLU\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.se = SEBlock(planes, reduction)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.se(out)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "##############################################\n",
        "# 5. 构造 SE-ResNet18 模型\n",
        "##############################################\n",
        "def get_se_resnet18():\n",
        "    # 使用 SEBasicBlock 替换 BasicBlock，层数与 ResNet18 相同：[2,2,2,2]\n",
        "    return ResNet(SEBasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def get_se_resnet18_improved():\n",
        "    model = get_se_resnet18()\n",
        "    replace_activation(model, nn.ReLU, Mish)\n",
        "    return model\n",
        "\n",
        "##############################################\n",
        "# 6. 模型结构验证增强（自动断言检查）\n",
        "##############################################\n",
        "def validate_model_structure():\n",
        "    model = get_se_resnet18_improved()\n",
        "    print(\"改进后的模型结构验证:\")\n",
        "    relu_count = sum(1 for _, module in model.named_modules() if isinstance(module, nn.ReLU))\n",
        "    assert relu_count == 0, f\"发现 {relu_count} 个未替换的 ReLU 层\"\n",
        "    seblock_count = sum(1 for _, module in model.named_modules() if isinstance(module, SEBasicBlock))\n",
        "    assert seblock_count > 0, \"未检测到 SE 模块\"\n",
        "    print(\"✅ 模型结构验证通过\")\n",
        "    return model\n",
        "\n",
        "##############################################\n",
        "# 7. 统一特征提取接口（包装器）\n",
        "##############################################\n",
        "class ResNetWrapper(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(ResNetWrapper, self).__init__()\n",
        "        self.base_model = base_model\n",
        "    def forward(self, x):\n",
        "        return self.base_model(x)\n",
        "    def get_features(self, x):\n",
        "        # 提取最后一个卷积层后的特征（avgpool 前后）\n",
        "        if hasattr(self.base_model, 'avgpool'):\n",
        "            x = self.base_model.conv1(x)\n",
        "            x = self.base_model.bn1(x)\n",
        "            x = self.base_model.relu(x)\n",
        "            x = self.base_model.maxpool(x)\n",
        "            x = self.base_model.layer1(x)\n",
        "            x = self.base_model.layer2(x)\n",
        "            x = self.base_model.layer3(x)\n",
        "            x = self.base_model.layer4(x)\n",
        "            x = self.base_model.avgpool(x)\n",
        "            return torch.flatten(x, 1)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "##############################################\n",
        "# 8. GPU监控（完善版，可选全程追踪）\n",
        "##############################################\n",
        "class GPUMonitor:\n",
        "    def __init__(self, full_trace=False):\n",
        "        self.full_trace = full_trace\n",
        "    def __enter__(self):\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        if self.full_trace:\n",
        "            self.profiler = torch.profiler.profile(\n",
        "                activities=[torch.profiler.ProfilerActivity.CUDA],\n",
        "                profile_memory=True\n",
        "            )\n",
        "            self.profiler.__enter__()\n",
        "        self.start_event = torch.cuda.Event(enable_timing=True)\n",
        "        self.end_event = torch.cuda.Event(enable_timing=True)\n",
        "        self.start_event.record()\n",
        "        return self\n",
        "    def __exit__(self, *args):\n",
        "        self.end_event.record()\n",
        "        torch.cuda.synchronize()\n",
        "        if self.full_trace:\n",
        "            self.profiler.__exit__(None, None, None)\n",
        "        self.mem_peak = torch.cuda.max_memory_allocated()\n",
        "\n",
        "##############################################\n",
        "# 9. KL 散度计算（对称 KL 散度）\n",
        "##############################################\n",
        "def compute_kl_div(model, train_loader, val_loader, device):\n",
        "    model.eval()\n",
        "    def get_all_probs(loader):\n",
        "        probs = []\n",
        "        with torch.no_grad():\n",
        "            for x, _ in loader:\n",
        "                x = x.to(device)\n",
        "                p = F.softmax(model(x), dim=1)\n",
        "                probs.append(p.cpu())\n",
        "        return torch.cat(probs)\n",
        "    p = get_all_probs(train_loader).mean(0)\n",
        "    q = get_all_probs(val_loader).mean(0)\n",
        "    kl_pq = entropy(p.numpy(), q.numpy())\n",
        "    kl_qp = entropy(q.numpy(), p.numpy())\n",
        "    return (kl_pq + kl_qp) / 2\n",
        "\n",
        "##############################################\n",
        "# 10. 显存压缩比计算（归一化到每样本）\n",
        "##############################################\n",
        "def compute_memory_ratio(base_mem, exp_mem, batch_size):\n",
        "    base_per_sample = base_mem / batch_size\n",
        "    exp_per_sample = exp_mem / batch_size\n",
        "    return (base_per_sample - exp_per_sample) / base_per_sample\n",
        "\n",
        "##############################################\n",
        "# 11. 评估函数：计算验证集损失和准确率\n",
        "##############################################\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "##############################################\n",
        "# 12. 训练阶段判断函数：基于 epoch 阶段切换\n",
        "##############################################\n",
        "def is_sprint_phase(epoch, config):\n",
        "    cycle = config['sprint_epochs'] + config['rest_epochs']\n",
        "    phase = epoch % cycle\n",
        "    return phase < config['sprint_epochs']\n",
        "\n",
        "##############################################\n",
        "# 13. 对抗攻击评估及可视化\n",
        "##############################################\n",
        "debug_mode = True  # 调试模式，首次可视化对抗样本\n",
        "\n",
        "def visualize_attack(original, adversarial):\n",
        "    device = original.device  # 确保均在同一设备\n",
        "    mean = torch.tensor([0.5, 0.5, 0.5], device=device).view(3, 1, 1)\n",
        "    std = torch.tensor([0.5, 0.5, 0.5], device=device).view(3, 1, 1)\n",
        "    original_denorm = torch.clamp(original * std + mean, 0, 1)\n",
        "    adversarial_denorm = torch.clamp(adversarial * std + mean, 0, 1)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_denorm.permute(1, 2, 0).cpu().numpy())\n",
        "    plt.title(\"Original\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(adversarial_denorm.permute(1, 2, 0).cpu().numpy())\n",
        "    plt.title(\"Adversarial\")\n",
        "    plt.savefig(\"adversarial_examples.png\")\n",
        "    plt.close()\n",
        "\n",
        "def pgd_attack(model, loader, device, eps=0.03, alpha=0.01, iters=10):\n",
        "    global debug_mode\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in loader:\n",
        "        x_adv = x.clone().detach().to(device)\n",
        "        y = y.to(device)\n",
        "        for _ in range(iters):\n",
        "            x_adv.requires_grad = True\n",
        "            outputs = model(x_adv)\n",
        "            loss = F.cross_entropy(outputs, y)\n",
        "            grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "            x_adv = x_adv.detach() + alpha * grad.sign()\n",
        "            x_adv = torch.max(torch.min(x_adv, x.to(device) + eps), x.to(device) - eps)\n",
        "            x_adv = torch.clamp(x_adv, 0, 1)\n",
        "        if debug_mode:\n",
        "            # 确保 x[0] 同样移至 device\n",
        "            visualize_attack(x[0].to(device), x_adv[0])\n",
        "            debug_mode = False  # 仅显示一次\n",
        "        with torch.no_grad():\n",
        "            outputs = model(x_adv)\n",
        "            _, pred = outputs.max(1)\n",
        "            correct += pred.eq(y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "##############################################\n",
        "# 14. 特征稳定性分析（重复推理计算标准差）\n",
        "##############################################\n",
        "def feature_stability(model, loader, device, repeats=10):\n",
        "    model.eval()\n",
        "    features_list = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(repeats):\n",
        "            feats = []\n",
        "            for x, _ in loader:\n",
        "                x = x.to(device)\n",
        "                feat = model.get_features(x)\n",
        "                feats.append(feat)\n",
        "            feats = torch.cat(feats, dim=0)\n",
        "            features_list.append(feats)\n",
        "    features_stack = torch.stack(features_list, dim=0)\n",
        "    stability = features_stack.std(dim=0).mean().item()\n",
        "    return stability\n",
        "\n",
        "##############################################\n",
        "# 15. 统计显著性分析\n",
        "##############################################\n",
        "def analyze_results(results):\n",
        "    metrics = []\n",
        "    for exp_name, runs in results.items():\n",
        "        for run in runs:\n",
        "            final_acc = run['val_acc'][-1]\n",
        "            metrics.append({'exp': exp_name, 'acc': final_acc})\n",
        "    df = pd.DataFrame(metrics)\n",
        "    groups = df.groupby('exp')['acc']\n",
        "    print(groups.describe())\n",
        "    baseline = df[df['exp'] == 'Baseline']['acc']\n",
        "    restwake = df[df['exp'] == 'Rest-Wake (原始架构)']['acc']\n",
        "    t_stat, p_val = stats.ttest_rel(baseline, restwake)\n",
        "    print(f\"配对 t 检验 p 值: {p_val:.4f}\")\n",
        "\n",
        "##############################################\n",
        "# 16. 学习曲线可视化函数\n",
        "##############################################\n",
        "def visualize_results(results):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    for exp, runs in results.items():\n",
        "        avg_loss = np.mean([r['train_loss'] for r in runs], axis=0)\n",
        "        plt.plot(avg_loss, label=exp)\n",
        "    plt.title(\"Training Loss\")\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 3, 2)\n",
        "    for exp, runs in results.items():\n",
        "        avg_acc = np.mean([r['val_acc'] for r in runs], axis=0)\n",
        "        plt.plot(avg_acc, label=exp)\n",
        "    plt.title(\"Validation Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 3, 3)\n",
        "    for exp, runs in results.items():\n",
        "        avg_mem = np.linspace(200, 500, num=len(runs[0]['train_loss']))\n",
        "        plt.plot(avg_mem, label=exp)\n",
        "    plt.title(\"GPU Memory Usage (MB)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_curves.png\")\n",
        "    plt.close()\n",
        "\n",
        "##############################################\n",
        "# 17. 配置验证函数\n",
        "##############################################\n",
        "def validate_config(config):\n",
        "    required_keys = ['lr', 'batch_size', 'num_epochs']\n",
        "    assert all(k in config for k in required_keys), \"缺少必要配置项\"\n",
        "    assert config['batch_size'] % 2 == 0, \"Batch size 应为2的倍数\"\n",
        "    assert 0 < config['lr'] < 1, \"学习率应在 (0,1) 范围内\"\n",
        "    assert config['sprint_epochs'] + config['rest_epochs'] <= config['num_epochs'] // 2, \"阶段周期过长\"\n",
        "    print(\"✅ 配置验证通过\")\n",
        "\n",
        "##############################################\n",
        "# 18. 特征维度一致性检查\n",
        "##############################################\n",
        "def validate_feature_dimension(model, device, input_size=(3, 32, 32)):\n",
        "    model.eval()  # 切换到评估模式\n",
        "    test_input = torch.randn(1, *input_size).to(device)\n",
        "    feat = model.get_features(test_input)\n",
        "    feat_dim = feat.shape[1]\n",
        "    # 根据 ResNet18 默认情况，预期特征维度为512；如有需要可调整\n",
        "    assert feat_dim == 512, f\"特征维度应为512，实际得到 {feat_dim}\"\n",
        "    print(\"✅ 特征维度验证通过\")\n",
        "\n",
        "##############################################\n",
        "# 19. 训练函数（包含自适应休息策略、动态调整限制、模型保存/加载）\n",
        "##############################################\n",
        "def train_model(config, experiment_name, train_loader, val_loader):\n",
        "    device = config['device']\n",
        "    num_epochs = config['num_epochs']\n",
        "\n",
        "    if config['arch'] == 'VanillaResNet':\n",
        "        base_model = resnet18(pretrained=False)\n",
        "        replace_activation(base_model, nn.ReLU, Mish)\n",
        "    elif config['arch'] == 'ResNet+SE+Mish':\n",
        "        base_model = get_se_resnet18_improved()\n",
        "    else:\n",
        "        raise ValueError(\"未知的模型架构\")\n",
        "\n",
        "    model = ResNetWrapper(base_model).to(device)\n",
        "\n",
        "    validate_feature_dimension(model, device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config['lr'],\n",
        "                          momentum=config['momentum'], weight_decay=config['weight_decay'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    prev_val_loss = None\n",
        "    smoothed_delta = 0.0\n",
        "\n",
        "    checkpoint_dir = \"checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if config['train_method'] == \"Rest-Wake\":\n",
        "            if is_sprint_phase(epoch, config):\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "                avg_train_loss = running_loss / len(train_loader)\n",
        "            else:\n",
        "                model.eval()\n",
        "                running_loss = 0.0\n",
        "                with torch.no_grad():\n",
        "                    for inputs, labels in train_loader:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        running_loss += loss.item()\n",
        "                avg_train_loss = running_loss / len(train_loader)\n",
        "        else:\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "            avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        current_val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(current_val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        if prev_val_loss is not None:\n",
        "            delta_val = (current_val_loss - prev_val_loss) / prev_val_loss\n",
        "            smoothed_delta = config['ema_beta'] * delta_val + (1 - config['ema_beta']) * smoothed_delta\n",
        "            if smoothed_delta < -0.05:\n",
        "                config['sprint_epochs'] = min(max(config['sprint_epochs'] + 1, 3), 7)\n",
        "                config['rest_epochs'] = max(config['rest_epochs'] - 1, 1)\n",
        "            elif smoothed_delta > 0.02:\n",
        "                config['rest_epochs'] = min(config['rest_epochs'] + 1, 3)\n",
        "                config['sprint_epochs'] = max(config['sprint_epochs'] - 1, 1)\n",
        "        prev_val_loss = current_val_loss\n",
        "\n",
        "        if current_val_loss < best_val_loss:\n",
        "            best_val_loss = current_val_loss\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'best_model_{experiment_name}.pth')\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "        with GPUMonitor(full_trace=False) as gpu_mon:\n",
        "            model.eval()\n",
        "            for inputs, _ in train_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                _ = model(inputs)\n",
        "                break\n",
        "\n",
        "        print(f\"实验: {experiment_name}, Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {current_val_loss:.4f}, Val Acc: {val_acc:.4f}, GPU峰值内存: {gpu_mon.mem_peak/1024**2:.2f} MB\")\n",
        "\n",
        "    best_model_path = os.path.join(checkpoint_dir, f'best_model_{experiment_name}.pth')\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    final_val_loss, final_val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    kl_div = compute_kl_div(model, train_loader, val_loader, device)\n",
        "    adv_acc = pgd_attack(model, val_loader, device)\n",
        "    feat_stability = feature_stability(model, val_loader, device)\n",
        "\n",
        "    print(f\"最终评估: Val Loss: {final_val_loss:.4f}, Val Acc: {final_val_acc:.4f}\")\n",
        "    print(f\"对称KL散度: {kl_div:.4f}\")\n",
        "    print(f\"对抗样本准确率: {adv_acc:.4f}\")\n",
        "    print(f\"特征稳定性 (标准差平均): {feat_stability:.4f}\")\n",
        "\n",
        "    return history, model\n",
        "\n",
        "##############################################\n",
        "# 20. 主函数：加载数据、验证配置并运行实验\n",
        "##############################################\n",
        "def main():\n",
        "    base_config = {\n",
        "        'lr': 0.1,\n",
        "        'batch_size': 256,\n",
        "        'weight_decay': 1e-4,\n",
        "        'momentum': 0.9,\n",
        "        'num_epochs': 50,\n",
        "        'ema_beta': 0.7,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'sprint_epochs': 5,\n",
        "        'rest_epochs': 1\n",
        "    }\n",
        "\n",
        "    validate_config(base_config)\n",
        "\n",
        "    experiment_matrix = {\n",
        "        'Baseline': {**base_config, 'arch': 'VanillaResNet', 'train_method': 'SGD'},\n",
        "        'Rest-Wake (原始架构)': {**base_config, 'arch': 'VanillaResNet', 'train_method': 'Rest-Wake'},\n",
        "        'Rest-Wake (改进架构)': {**base_config, 'arch': 'ResNet+SE+Mish', 'train_method': 'Rest-Wake'}\n",
        "    }\n",
        "\n",
        "    validate_model_structure()\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                                 download=True, transform=transform_train)\n",
        "    val_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                               download=True, transform=transform_test)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=base_config['batch_size'],\n",
        "                                               shuffle=True, num_workers=2)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=base_config['batch_size'],\n",
        "                                             shuffle=False, num_workers=2)\n",
        "\n",
        "    num_repeats = 3\n",
        "    results = {}\n",
        "\n",
        "    for exp_name, config in experiment_matrix.items():\n",
        "        exp_histories = []\n",
        "        for seed in range(num_repeats):\n",
        "            print(f\"\\n运行实验组 {exp_name}，重复 {seed+1}\")\n",
        "            torch.manual_seed(seed)\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.manual_seed(seed)\n",
        "            history, model = train_model(config, exp_name, train_loader, val_loader)\n",
        "            exp_histories.append(history)\n",
        "        results[exp_name] = exp_histories\n",
        "\n",
        "    base_mem = 500 * 1024**2\n",
        "    exp_mem = 400 * 1024**2\n",
        "    memory_ratio = compute_memory_ratio(base_mem, exp_mem, base_config['batch_size'])\n",
        "    print(f\"显存压缩比: {memory_ratio:.4f}\")\n",
        "\n",
        "    analyze_results(results)\n",
        "    visualize_results(results)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}